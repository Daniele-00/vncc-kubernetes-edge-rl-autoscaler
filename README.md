# ‚ö° Kubernetes Edge Cloud with RL Autoscaler

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](#)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Minikube-326ce5?logo=kubernetes&logoColor=white)](#)
[![Docker](https://img.shields.io/badge/Docker-Container-2496ed?logo=docker&logoColor=white)](#)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit&logoColor=white)](#)
[![License: MIT](https://img.shields.io/badge/License-MIT-green)](#license)

> Progetto per l‚Äôinsegnamento **Virtual Networks and Cloud Computing** (a.a. **2024/25**)  
> Autore: **Daniele Nanni Cirulli**

Questo progetto implementa un **Edge Cloud Autoscaler** su **Kubernetes** basato su **Reinforcement Learning (Q-Learning)**.  
L‚Äôagente apprende autonomamente come scalare le risorse (Pod) per mantenere bassa la latenza minimizzando i costi, ed √® confrontato con un approccio tradizionale **rule-based** (baseline a soglia fissa).

---

## üìö Indice

- [üì∏ Dashboard Preview](#-dashboard-preview)
- [üåü Caratteristiche Principali](#-caratteristiche-principali)
- [üèóÔ∏è Architettura del Sistema](#Ô∏è-architettura-del-sistema)
- [üìÅ Struttura del Progetto](#-struttura-del-progetto)
- [üöÄ Installazione](#-installazione)
- [üéÆ Esecuzione della Demo](#-esecuzione-della-demo)
- [üß™ Metodologia di Confronto (Workflow Tesi)](#-metodologia-di-confronto-workflow-tesi)
- [üß† Teoria: Q-Learning Setup](#-teoria-q-learning-setup)
- [‚úÖ Risultati Ottenuti](#-risultati-ottenuti)
- [üìÑ License](#-license)

---

## üì∏ Dashboard Preview

> Inserisci qui uno screenshot della Dashboard in modalit√† **Confronto Diretto**.

![Dashboard Screenshot](results/dashboard_preview.png)

---

## üåü Caratteristiche Principali

- **üß† Agente RL intelligente:** Q-Learning per apprendere la policy di scaling senza regole preimpostate.
- **‚öñÔ∏è Baseline comparison:** autoscaler tradizionale (rule-based) per confronto sperimentale.
- **üìä Control Center interattivo:** dashboard Streamlit per monitorare metriche in tempo reale, cambiare scenari di traffico e modificare soglie SLA ‚Äúon the fly‚Äù.
- **üåä Traffic injection:** generatore di carico per simulare scenari realistici (*Calma, Spike, Onda sinusoidale, Stop*).
- **üê≥ Cloud-native:** containerizzazione + orchestrazione su Kubernetes (Minikube).

> Nota: anche la baseline produce uno **score/reward di valutazione** (calcolato a posteriori) per poter confrontare baseline e RL sulla **stessa metrica**. La baseline **non** usa tale reward per decidere.

---

## üèóÔ∏è Architettura del Sistema

Il sistema √® un loop di controllo chiuso (MAPE Loop: *Monitor, Analyze, Plan, Execute*).

```mermaid
flowchart LR
    %% Generatore Traffico
    LG[("Load Generator")] -- HTTP Requests --> SVC(Service NodePort)

    %% Cluster K8s
    subgraph K8s [Kubernetes Cluster]
        SVC --> POD1[App Pod]
        SVC --> POD2[App Pod]
        DEP[Deployment edge-app] -.-> POD1 & POD2
    end

    %% Autoscaler Logic
    POD1 -->|Metrics (Latency)| RL[üß† RL Autoscaler]
    RL -->|Action (Scale UP/DOWN)| DEP

    %% Monitoring
    RL -->|Writes| LOG[(CSV Logs)]
    LOG --> DASH[üìä Streamlit Dashboard]
    DASH -- Config (SLA) --> RL
```

---

## üìÅ Struttura del Progetto

```text
kube-rl-edge/
‚îú‚îÄ‚îÄ app/                  # Microservizio Edge (Flask) + Dockerfile
‚îú‚îÄ‚îÄ k8s/                  # Manifest Kubernetes (Deployment + Service)
‚îú‚îÄ‚îÄ autoscaler/           # Logica di Autoscaling
‚îÇ   ‚îú‚îÄ‚îÄ rl_autoscaler.py        # Agente Q-Learning
‚îÇ   ‚îî‚îÄ‚îÄ baseline_autoscaler.py  # Autoscaler Rule-Based
‚îú‚îÄ‚îÄ load/                 # Generatore di traffico (Python)
‚îú‚îÄ‚îÄ results/              # CSV log e output (grafici/screenshot)
‚îú‚îÄ‚îÄ dashboard_ultra.py    # Control Center (Web UI)
‚îú‚îÄ‚îÄ plot_results.py       # Script per generare grafici (tesi)
‚îî‚îÄ‚îÄ requirements.txt      # Dipendenze Python
```

---

## üöÄ Installazione

### 1) Prerequisiti

- Docker Desktop (o Docker Engine su Linux)
- Minikube & kubectl
- Python 3.10+

### 2) Setup iniziale

Clona il repository e prepara l‚Äôambiente virtuale:

```bash
git clone https://github.com/Daniele-00/vncc-kubernetes-edge-rl-autoscaler.git
cd vncc-kubernetes-edge-rl-autoscaler

python3 -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### 3) Avvio del cluster

Avvia Minikube e deploya l‚Äôapplicazione:

```bash
minikube start --driver=docker
eval $(minikube docker-env)             # usa il Docker daemon di Minikube

docker build -t edge-app:latest ./app
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml       # se presente
```

Verifica che tutto sia pronto:

```bash
kubectl get pods
# Attendi che lo stato sia Running
```

---

## üéÆ Esecuzione della Demo

Per una dimostrazione completa, apri **4 terminali**:

### Terminale 1 ‚Äî Monitor Kubernetes

Osserva i Pod crearsi/distruggersi in tempo reale:

```bash
kubectl get deploy edge-app -w
```

### Terminale 2 ‚Äî Generatore di carico

Inietta traffico HTTP verso il cluster:

```bash
export MINIKUBE_IP=$(minikube ip)
python load/load_generator.py
```

> Nota: lo scenario si comanda dalla Dashboard.

### Terminale 3 ‚Äî Autoscaler

Scegli se avviare l‚Äôagente RL o la baseline.

**Opzione A: Reinforcement Learning**
```bash
export MINIKUBE_IP=$(minikube ip)
python autoscaler/rl_autoscaler.py
```

**Opzione B: Baseline (Rule-Based)**
```bash
export MINIKUBE_IP=$(minikube ip)
python autoscaler/baseline_autoscaler.py
```

### Terminale 4 ‚Äî Dashboard (Control Center)

```bash
streamlit run dashboard_ultra.py
```

Apri il browser all‚Äôindirizzo mostrato (es. `http://localhost:8501`).

---

## üß™ Metodologia di Confronto (Workflow Tesi)

Per riprodurre i grafici di confronto:

1. Avvia `rl_autoscaler.py` e imposta lo scenario **Onda** dalla Dashboard.
2. Lascia girare per ~10 minuti (training), poi ferma lo script (**Ctrl+C**).
3. Resetta il cluster:
   ```bash
   kubectl scale deploy edge-app --replicas=1
   ```
4. Avvia `baseline_autoscaler.py` con lo **stesso scenario**.
5. Lascia girare per ~5 minuti, poi ferma lo script.
6. Nella Dashboard seleziona **‚öîÔ∏è CONFRONTO DIRETTO**.
7. Esegui lo script di plotting (adatta al tuo nome file):
   ```bash
   python plot_compare.py
   ```
   per generare PNG/HTML per la documentazione.

---

## üß† Teoria: Q-Learning Setup

Il problema √® modellato come un **MDP (Markov Decision Process)**:

- **Stato** \(S\): tupla \(\{Latency\_Bucket, Current\_Replicas\}\)
- **Azione** \(A\): *Scale UP* (+1), *Scale DOWN* (-1), *Hold* (0)
- **Reward** \(R\):
  \[
  R = R_{SLA} - (C_{cost} \times N_{replicas})
  \]
  dove \(R_{SLA}\) √® positivo se la latenza < target e negativo se > critica.

**Aggiornamento della Q-table:**
\[
Q(s,a) \leftarrow Q(s,a) + \alpha \left[r + \gamma \max_{a'} Q(s',a') - Q(s,a)\right]
\]

---

## ‚úÖ Risultati Ottenuti

L‚Äôagente RL dimostra di saper:

- **Ridurre i costi** diminuendo le repliche quando il traffico cala, pi√π rapidamente della baseline.
- **Stabilizzare il sistema** evitando l‚Äôeffetto ‚Äúyo-yo‚Äù (*flapping*) tipico degli algoritmi a soglia fissa.
- **Adattarsi a SLA dinamici** modificati in tempo reale tramite la Dashboard.

---

## üí° Consigli per fare bella figura

1. **Screenshot:** fai uno screenshot reale della dashboard in modalit√† *Confronto Diretto* e salvalo come `results/dashboard_preview.png`. Verr√† mostrato automaticamente nel README.
2. **IP Minikube:** l‚Äôuso di `export MINIKUBE_IP=$(minikube ip)` evita di modificare il codice ogni volta.
   - Windows PowerShell:  
     ```powershell
     $env:MINIKUBE_IP = (minikube ip)
     ```
3. **Diagramma Mermaid:** GitHub renderizza nativamente il diagramma Mermaid ed √® perfetto per la relazione.

---

## üìÑ License

Distribuito sotto licenza **MIT**. Vedi `LICENSE` per dettagli.
