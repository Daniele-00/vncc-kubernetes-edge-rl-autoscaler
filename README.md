# <img src="logo/logo_vncc.png" alt="Logo" width="32"> Kubernetes Edge Cloud with RL Autoscaler

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)](#)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-Minikube-326ce5?logo=kubernetes&logoColor=white)](#)
[![Docker](https://img.shields.io/badge/Docker-Container-2496ed?logo=docker&logoColor=white)](#)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit&logoColor=white)](#)
[![License: MIT](https://img.shields.io/badge/License-MIT-green)](#license)

> Progetto per l‚Äôinsegnamento **Virtual Networks and Cloud Computing** (a.a. **2024/25**)  
> Autore: **Daniele Nanni Cirulli**

Questo progetto implementa un **Edge Cloud Autoscaler** su **Kubernetes** basato su **Reinforcement Learning (Q-Learning)**.  
L‚Äôagente apprende autonomamente come scalare le risorse (Pod) per mantenere bassa la latenza minimizzando i costi, ed √® confrontato con un approccio tradizionale **rule-based** (baseline a soglia fissa).

---

## üìö Indice

- [üì∏ Dashboard Preview](#-dashboard-preview)
- [üåü Caratteristiche Principali](#-caratteristiche-principali)
- [üèóÔ∏è Architettura del Sistema](#Ô∏è-architettura-del-sistema)
- [üìÅ Struttura del Progetto](#-struttura-del-progetto)
- [üöÄ Installazione](#-installazione)
- [üéÆ Esecuzione della Demo](#-esecuzione-della-demo)
- [üß™ Metodologia di Confronto (Workflow Tesi)](#-metodologia-di-confronto-workflow-tesi)
- [üß† Teoria: Q-Learning Setup](#-teoria-q-learning-setup)
- [‚úÖ Risultati Ottenuti](#-risultati-ottenuti)
- [üìÑ License](#-license)

---

## üì∏ Dashboard Preview

> Inserisci qui uno screenshot della Dashboard in modalit√† **Confronto Diretto**.

![Dashboard Screenshot](results/dashboard_preview.png)

---

## üåü Caratteristiche Principali

- **üß† Agente RL intelligente:** Q-Learning per apprendere la policy di scaling senza regole preimpostate.
- **‚öñÔ∏è Baseline comparison:** autoscaler tradizionale (rule-based) per confronto sperimentale.
- **üìä Control Center interattivo:** dashboard Streamlit per monitorare metriche in tempo reale, cambiare scenari di traffico e modificare soglie SLA ‚Äúon the fly‚Äù.
- **üåä Traffic injection:** generatore di carico per simulare scenari realistici (*Calma, Spike, Onda sinusoidale, Stop*).
- **üê≥ Cloud-native:** containerizzazione + orchestrazione su Kubernetes (Minikube).

> Nota: anche la baseline produce uno **score/reward di valutazione** (calcolato a posteriori) per poter confrontare baseline e RL sulla **stessa metrica**. La baseline **non** usa tale reward per decidere.

---

## üèóÔ∏è Architettura del Sistema

Il sistema √® un loop di controllo chiuso (MAPE Loop: *Monitor, Analyze, Plan, Execute*).

```mermaid
flowchart TB
    subgraph External["üåê External Traffic"]
        USER[("üë§ User/Client")]
    end
    
    subgraph LoadGen["‚ö° Load Generator"]
        LG["Load Controller(Python Multi-Thread)"]
        W1["Worker 1"]
        W2["Worker 2"]
        W3["Worker ..."]
        W15["Worker 15"]
        
        LG -->|Controlla frequenza| W1 & W2 & W3 & W15
    end
    
    subgraph K8s["‚ò∏Ô∏è Kubernetes Cluster (Minikube)"]
        subgraph Network["üîÄ Networking Layer"]
            SVC["Serviceedge-app-service(NodePort 30080)"]
        end
        
        subgraph Workload["üì¶ Application Layer"]
            POD1["Pod 1Flask App(200ms delay)"]
            POD2["Pod 2Flask App(200ms delay)"]
            POD3["Pod NFlask App(200ms delay)"]
        end
        
        subgraph Control["üéõÔ∏è Control Plane"]
            DEP["Deploymentedge-app(1-5 replicas)"]
            API["Kubernetes APIServer"]
        end
        
        SVC -->|Load Balancing| POD1 & POD2 & POD3
        DEP -.->|Gestisce| POD1 & POD2 & POD3
        API -->|CRUD Pods| DEP
    end
    
    subgraph Autoscaler["ü§ñ Autoscaling Layer"]
        RL["RL Autoscaler(Q-Learning)---‚Ä¢ Osserva: Latency, Replicas‚Ä¢ Decide: Azione [-1,0,+1]‚Ä¢ Apprende: Q-Table Update"]
        BASE["Baseline Autoscaler(Rule-Based)---‚Ä¢ IF lat > HIGH: +1‚Ä¢ IF lat < LOW: -1"]
    end
    
    subgraph Monitor["üìà Monitoring & Control"]
        DASH["Streamlit Dashboard---‚Ä¢ Real-time Metrics‚Ä¢ SLA Configuration‚Ä¢ Traffic Scenarios‚Ä¢ RL vs Baseline Comparison"]
        LOG[("CSV Logsrl_log.csvbaseline_log.csv")]
        CONFIG[("Config Filesautoscaler_config.jsoncurrent_scenario.txt")]
    end
    
    USER -->|HTTP Requests| W1 & W2 & W3 & W15
    W1 & W2 & W3 & W15 -->|"http://MINIKUBE_IP:30080"| SVC
    
    POD1 & POD2 & POD3 -->|"Metriche(Latency)"| RL & BASE
    RL & BASE -->|"kubectl scale--replicas=N"| API
    
    RL & BASE -->|Scrive metriche| LOG
    LOG -->|Legge dati| DASH
    DASH -->|Aggiorna config| CONFIG
    CONFIG -.->|Hot-reload| RL & BASE & LG
    
    classDef userClass fill:#e1f5ff,stroke:#0288d1,stroke-width:2px
    classDef loadClass fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    classDef k8sClass fill:#e8f5e9,stroke:#388e3c,stroke-width:2px
    classDef autoClass fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef monitorClass fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class USER userClass
    class LG,W1,W2,W3,W15 loadClass
    class SVC,POD1,POD2,POD3,DEP,API k8sClass
    class RL,BASE autoClass
    class DASH,LOG,CONFIG monitorClass
```

---

## üìÅ Struttura del Progetto

```text
kube-rl-edge/
‚îú‚îÄ‚îÄ app/                  # Microservizio Edge (Flask) + Dockerfile
‚îú‚îÄ‚îÄ k8s/                  # Manifest Kubernetes (Deployment + Service)
‚îú‚îÄ‚îÄ autoscaler/           # Logica di Autoscaling
‚îÇ   ‚îú‚îÄ‚îÄ rl_autoscaler.py        # Agente Q-Learning
‚îÇ   ‚îî‚îÄ‚îÄ baseline_autoscaler.py  # Autoscaler Rule-Based
‚îú‚îÄ‚îÄ load/                 # Generatore di traffico (Python)
‚îú‚îÄ‚îÄ results/              # CSV log e output (grafici/screenshot)
‚îú‚îÄ‚îÄ dashboard_ultra.py    # Control Center (Web UI)
‚îú‚îÄ‚îÄ plot_results.py       # Script per generare grafici (tesi)
‚îî‚îÄ‚îÄ requirements.txt      # Dipendenze Python
```

---

## üöÄ Installazione

### 1) Prerequisiti

- Docker Desktop (o Docker Engine su Linux)
- Minikube & kubectl
- Python 3.10+

### 2) Setup iniziale

Clona il repository e prepara l‚Äôambiente virtuale:

```bash
git clone https://github.com/Daniele-00/vncc-kubernetes-edge-rl-autoscaler.git
cd vncc-kubernetes-edge-rl-autoscaler

python3 -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### 3) Avvio del cluster

Avvia Minikube e deploya l‚Äôapplicazione:

```bash
minikube start --driver=docker
eval $(minikube docker-env)             # usa il Docker daemon di Minikube

docker build -t edge-app:latest ./app
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml       # se presente
```

Verifica che tutto sia pronto:

```bash
kubectl get pods
# Attendi che lo stato sia Running
```

---

## üéÆ Esecuzione della Demo

Per una dimostrazione completa, apri **4 terminali**:

### Terminale 1 ‚Äî Monitor Kubernetes

Osserva i Pod crearsi/distruggersi in tempo reale:

```bash
kubectl get deploy edge-app -w
```

### Terminale 2 ‚Äî Generatore di carico

Inietta traffico HTTP verso il cluster:

```bash
export MINIKUBE_IP=$(minikube ip)
python load/load_generator.py
```

> Nota: lo scenario si comanda dalla Dashboard.

### Terminale 3 ‚Äî Autoscaler

Scegli se avviare l‚Äôagente RL o la baseline.

**Opzione A: Reinforcement Learning**
```bash
export MINIKUBE_IP=$(minikube ip)
python autoscaler/rl_autoscaler.py
```

**Opzione B: Baseline (Rule-Based)**
```bash
export MINIKUBE_IP=$(minikube ip)
python autoscaler/baseline_autoscaler.py
```

### Terminale 4 ‚Äî Dashboard (Control Center)

```bash
streamlit run dashboard_ultra.py
```

Apri il browser all‚Äôindirizzo mostrato (es. `http://localhost:8501`).

---

## üß™ Metodologia di Confronto (Workflow Tesi)

Per riprodurre i grafici di confronto:

1. Avvia `rl_autoscaler.py` e imposta lo scenario **Onda** dalla Dashboard.
2. Lascia girare per ~10 minuti (training), poi ferma lo script (**Ctrl+C**).
3. Resetta il cluster:
   ```bash
   kubectl scale deploy edge-app --replicas=1
   ```
4. Avvia `baseline_autoscaler.py` con lo **stesso scenario**.
5. Lascia girare per ~5 minuti, poi ferma lo script.
6. Nella Dashboard seleziona **‚öîÔ∏è CONFRONTO DIRETTO**.
7. Esegui lo script di plotting (adatta al tuo nome file):
   ```bash
   python plot_compare.py
   ```
   per generare PNG/HTML per la documentazione.

---

## üß† Teoria: Q-Learning Setup

Il problema √® modellato come un **MDP** (Markov Decision Process):

* **Stato ($S$):** Tupla composta da `{Latency_Bucket, Current_Replicas}`.
* **Azione ($A$):** Insieme discreto `{-1, 0, +1}` (Scale DOWN, Hold, Scale UP).
* **Reward ($R$):**
    $$R = R_{SLA} - (C_{cost} \times N_{replicas})$$
    Dove $R_{SLA}$ √® un valore positivo (es. +5) se la latenza √® sotto il target, e negativo (es. -5) se supera la soglia critica. $C_{cost}$ √® il peso del costo per ogni replica attiva.

* **Q-Table Update (Bellman Equation):**
    $$Q(s,a) \leftarrow Q(s,a) + \alpha \left[ r + \gamma \max_{a'} Q(s',a') - Q(s,a) \right]$$
    
    Dove:
    * $\alpha$: Learning Rate (velocit√† di apprendimento)
    * $\gamma$: Discount Factor (importanza del futuro)

---

## ‚úÖ Risultati Ottenuti

L‚Äôagente RL dimostra di saper:

- **Ridurre i costi** diminuendo le repliche quando il traffico cala, pi√π rapidamente della baseline.
- **Stabilizzare il sistema** evitando l‚Äôeffetto ‚Äúyo-yo‚Äù (*flapping*) tipico degli algoritmi a soglia fissa.
- **Adattarsi a SLA dinamici** modificati in tempo reale tramite la Dashboard.

---

## üí° Consigli per fare bella figura

1. **Screenshot:** fai uno screenshot reale della dashboard in modalit√† *Confronto Diretto* e salvalo come `results/dashboard_preview.png`. Verr√† mostrato automaticamente nel README.
2. **IP Minikube:** l‚Äôuso di `export MINIKUBE_IP=$(minikube ip)` evita di modificare il codice ogni volta.
   - Windows PowerShell:  
     ```powershell
     $env:MINIKUBE_IP = (minikube ip)
     ```
3. **Diagramma Mermaid:** GitHub renderizza nativamente il diagramma Mermaid ed √® perfetto per la relazione.

---

## üìÑ License

Distribuito sotto licenza **MIT**. Vedi `LICENSE` per dettagli.
